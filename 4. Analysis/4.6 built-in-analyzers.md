[Built in analyzers](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html)

* Standard Analyzer (standard). Divides text into terms using Unicode Text Segmentation. Removes punctuation, lowercases ters, optionaly removes stop words. It's a wapper around a stadard tokenizer, the standard token filter and a lowercase filter and optionaly, the stopwords token filter. 
* Simple Analyzer (simple). Divides text into terms when encountering a character that is not a letter. Also lowercases all terms.
  `I'm in the mood for drinking semi-dri red wine! -> [i, m, in, the, mood, for, drinking, semi, dry, red, wine]`
* Stop Analyzer (stop). Like the simple analyzer, but also removes stop words
  `I'm in the mood for drinking semi-dri red wine! -> [i, in, mood, drinking, semi, dry, red, wine]`
* Language Analyzers (english, ..). Used for analyzing text in specific languages and provide a very easy way of enabling stemming, stop words and more without having to define these parts explicitely.
  `I'm in the mood for drinking semi-dri red wine! -> [i'n, mood, drink, semi, dry, red, wine]`
* Keyword Analyzer (keyword). No-op analyzer that returns the input as a single term. 
* Pattern Analyzer (pattern). Uses regex to match token separators and splits text into terms where matches occur.
* Whitespace Analyzer (whitespace). It's just a wrapper around whitespace tokenizer.   
