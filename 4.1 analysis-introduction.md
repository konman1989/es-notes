## Overview

When adding a new doc to ES, text fields are run through an analysis process. These are full text fields, not keyword fields.
```
New document -> analysis -> store document
```

It involves tokenizing text into terms, lowercasing text, etc. Analysis process takes tokenizing and normalizing text. This is done to make the text easier to search. The analyzed terms are stored in the inverted index. This means when we performm search queries we actualy search through the results of the analysis process. And not the documents as they were when we added them to the index. 


## Analyzer

Consists of three things: character filters, token filters and the tokenizer. Analyzer is basicaly a package of these building blocks with each one of them changing the input stream. So when idnexing a document it goes through the following flow:

* series or more character filters can be added
* a character filter recieved a text fields, original text and can the transform the value by adding, removing or changing characters
* afterwords a tokenizers splits the text into individual tokens which will usualy be words.

So if we have a sentence of 10 words, we would get an array of 10 tokens. 

**An analyzer may only have one tokenizer**. By default a tokenizer named standard is used which uses a unicode text segmentation algorythm. Without going into details it basicaly splits by whitespace and also removes most symbols as commas, oeriods, semi-colons etc. Besides the splitting words into tokens, tokenizer is also responsible for recording the position of the tokens including the start and end character offsets for the words that the tokens represent. 

When ES detects a string field it configures it as a full text field and applies the standard analyzer. This happens automaticaly unless you instruct the ES to do otherwise. 

```
I'm in the mood for drinking semi-dry red wine! -> [TOKENIZER] [I'm, in, the, mood, for, drinking, semi, dry, wine] -> [TOKEN FILTERS] [i'm, in, the, mood, for, drinking, semi, dry, wine]
```

```
POST /_analyze
{
  "tokenizer": "standard",
  "text":  "I'm in the mood for drinking semi-dry red wine!"
}
```

Response

```
{
  "tokens" : [
    {
      "token" : "I'm",
      "start_offset" : 0,
      "end_offset" : 3,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "in",
      "start_offset" : 4,
      "end_offset" : 6,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "the",
      "start_offset" : 7,
      "end_offset" : 10,
      "type" : "<ALPHANUM>",
      "position" : 2
    },
    {
      "token" : "mood",
      "start_offset" : 11,
      "end_offset" : 15,
      "type" : "<ALPHANUM>",
      "position" : 3
    },
    {
      "token" : "for",
      "start_offset" : 16,
      "end_offset" : 19,
      "type" : "<ALPHANUM>",
      "position" : 4
    },
    {
      "token" : "drinking",
      "start_offset" : 20,
      "end_offset" : 28,
      "type" : "<ALPHANUM>",
      "position" : 5
    },
    {
      "token" : "semi",
      "start_offset" : 29,
      "end_offset" : 33,
      "type" : "<ALPHANUM>",
      "position" : 6
    },
    {
      "token" : "dry",
      "start_offset" : 34,
      "end_offset" : 37,
      "type" : "<ALPHANUM>",
      "position" : 7
    },
    {
      "token" : "red",
      "start_offset" : 38,
      "end_offset" : 41,
      "type" : "<ALPHANUM>",
      "position" : 8
    },
    {
      "token" : "wine",
      "start_offset" : 42,
      "end_offset" : 46,
      "type" : "<ALPHANUM>",
      "position" : 9
    }
  ]
}
```

```
POST /_analyze
{
  "filter": ["lowercase"],
  "text":  "I'm in the mood for drinking semi-dry red wine!"
}
```
Response
```
{
  "tokens" : [
    {
      "token" : "i'm in the mood for drinking semi-dry red wine!",
      "start_offset" : 0,
      "end_offset" : 47,
      "type" : "word",
      "position" : 0
    }
  ]
}
```

[List of language analyzers](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html)


